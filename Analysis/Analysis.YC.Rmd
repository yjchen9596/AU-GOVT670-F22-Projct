---
title: "NBA Multilevel Model"
author: "Yuka Chen"
date: "`r Sys.Date()`"
output: pdf_document
---

# Loading libraries
```{r include=FALSE}
library(tidyverse)
library(ISLR)
library(tidymodels)
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(caret)
library(pROC)
library(tree)
library(broom)
library(kableExtra)
library(MASS)
library(arm)
library(leaps)
```

# Loading data
```{r include=FALSE}
df_dc<- read_rds("../Data/cases.after2010.rds")

#Dropping the variables that are not useful for prediction or with many levels i.e Licence plate state, Vehicle type
df_analysis<- df_dc %>%
dplyr::select(-c(PERSONID,MAR_ID, NEARESTINTSTREETNAME, NEARESTINTROUTEID, YCOORD, XCOORD, LONGITUDE,LATITUDE, ADDRESS, FROMDATE, REPORTDATE, X, Y, CCN,  MEASURE,OFFSET,VEHICLEID, date, time, year, CRIMEID, ROUTEID, INTAPPROACHDIRECTION, INVEHICLETYPE, LICENSEPLATESTATE))

#Changing variables to factors
fact_vars <- c('WARD', 'SPEEDING_INVOLVED', 'PERSONTYPE', 'FATAL', 'MAJORINJURY', 'MINORINJURY', 'TICKETISSUED','SPEEDING','IMPAIRED', 'time_period')
df_analysis[,fact_vars] <- lapply(df_analysis[,fact_vars] , factor)

# fit a logistic regression model using all of the predictor variables
df_analysis |> 
  mutate(FATAL = ifelse(FATAL == "Y", 1, 0)) |> 
  filter(AGE >= 16 & AGE < 90) |> 
  dplyr::select(FATAL, everything())-> df_analysis

# set all columns cap
df_analysis <- df_analysis %>% rename_all(toupper)

## You must be at least 16 years old to get a DC DMV learner permit, and you must pass vision screening and knowledge tests and provide documentation that proves your identity, residency, and eligibility, among other things. DC DMV offers learners either a REAL ID or a Limited Purpose learner permit
glimpse(df_analysis)
```

# Get variables name 
```{r}
# column_names <- colnames(df_analysis)
# cat(paste(column_names), collapse = ", ")
# dput(as.character(column_names))
```

# Variables Summary
```{r}

data_frame <- df_analysis

# calculate the mean number of total vehicles involved in collisions by ward
mean_vehicles_by_ward <- aggregate(TOTAL_VEHICLES ~ WARD, data_frame, mean)

# print the mean number of vehicles by ward
print(mean_vehicles_by_ward)

# calculate the mean number of total bicycles involved in collisions by ward
mean_bicycles_by_ward <- aggregate(TOTAL_BICYCLES ~ WARD, data_frame, mean)

# print the mean number of bicycles by ward
print(mean_bicycles_by_ward)

# calculate the mean number of total pedestrians involved in collisions by ward
mean_pedestrians_by_ward <- aggregate(TOTAL_PEDESTRIANS ~ WARD, data_frame, mean)

# print the mean number of pedestrians by ward
print(mean_pedestrians_by_ward)

```
```{r}
df_analysis |> 
  group_by(PERSONTYPE) |> 
  summarise("Numbers of Accidents"=n()) |> 
   knitr::kable("latex", booktabs = T) %>%
  kable_styling() %>%
  save_kable(file = "PERSONTYPE.png",
             zoom = 1.5,
             bs_theme = "Sandstone")
```
```{r}
options(scipen=10000)
ggthemr("fresh")

df_analysis |> 
  ggplot(aes(x = PERSONTYPE))+
  geom_bar()+
  coord_flip()+
  labs(y = "Numbers of Accidents",
       title ="Distribution of Person Types",
       x = "")+
  scale_y_continuous()+
theme(plot.title = element_text(hjust = 0.5))

  
```
```{r}
options(scipen=10000)

ggthemr("fresh")

df_analysis |> 
  group_by(WARD) |> 
  summarise("Numbers of Accidents"=n()) |> 
    knitr::kable("latex", booktabs = T) %>%
  kable_styling() %>%
  save_kable(file = "ward.png",
             zoom = 1.5,
             bs_theme = "Sandstone")
```

```{r}
df_analysis |> 
  ggplot(aes(x = WARD))+
  geom_bar()+
  coord_flip()+
  labs(y = "Numbers of Accidents")+
  scale_y_continuous()
```




#Logistic Regression with the full data set

```{r}
full.model <- glm(FATAL ~ ., data = df_analysis, family = "binomial")
display(full.model)
```

#Logistic Regression with the partial data set

```{r}
# load the caret package
library(caret)

df_analysis$FATAL <- as.factor(df_analysis$FATAL)
# split the data into training and test sets
train_indices <- createDataPartition(df_analysis$FATAL, p = 0.7, list = FALSE)
train <- df_analysis[train_indices,]
test <- df_analysis[-train_indices,]

library(tune)
tuneGrid = expand.grid(interaction.depth = c(1, 5, 9), 
                        n.trees = (1:30)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20)

# train a logistic regression model using the training data
model <- train(FATAL ~ TIME_PERIOD + MONTH + SPEEDING + AGE + WARD + TOTAL_GOVERNMENT, 
               data = train, 
               method = "glm", 
               family = "binomial",
               trControl = trainControl(method = "cv"))

# generate a summary of the model's performance using the test data
confusionMatrix(test$FATAL, predict(model, newdata = test))

```

#Stepwise
```{r}
df_dc |> 
  slice_sample(n = 5000) -> df_dc2


df_dc2 |> 
  mutate(FATAL = ifelse(FATAL == "Y", 1, 0)) |> 
  filter(AGE >= 16 & AGE < 90) |> 
  dplyr::select(FATAL, everything()) |> 
  rename_all(toupper)-> df_dc3

# Fit a logistic regression model to your data
model <- glm(FATAL ~ INTAPPROACHDIRECTION+TIME_PERIOD + MONTH + SPEEDING_INVOLVED + AGE + WARD + PERSONTYPE + INVEHICLETYPE+NEARESTINTSTREETNAME+YEAR+ TIME, data = df_dc3, family = "binomial")

# Perform a stepwise regression
step_model <- stepAIC(model, direction = "both")
```



```{r}
# Print the summary of the stepwise model
summary(step_model)

tidy(step_model) |> 
  dplyr::arrange(p.value) |> 
    knitr::kable("latex", booktabs = T) %>%
  kable_styling() %>%
  save_kable(file = "../Output/stepwise.png",
             zoom = 1.5,
             bs_theme = "Sandstone")
```
# Initial Logit
```{r}

df_dc<- read_rds("../Data/cases.after2010.rds")


df_dc |> mutate(PERSONTYPE = recode(PERSONTYPE, 
                       "0" = "Unknown", 
                     "Occupant o" = "Unknown", 
                     "Other" = "Unknown", 
                     "Unknown" = "Unknown",
                     "Electric M" = "ElectricalCar"),
                     WARD = as.character(WARD),
                     PERSONTYPE = as.character(PERSONTYPE)) |> 
  mutate(FATAL = ifelse(FATAL == "Y", 1, 0)) |> 
    filter(AGE >= 16 & AGE < 90) |> 
  mutate(WARD = if_else(WARD %in% c("Null", "UNKNOWN"), "Unknown", WARD),
         FATAL = if_else(FATAL == 1, 0, 1),
         SPEEDING_INVOLVED = if_else(SPEEDING_INVOLVED == 1, 0, 1)) |> 
        filter(PERSONTYPE !=  "Unknown" &  PERSONTYPE !=  "Witness" & PERSONTYPE !=  "Reporting") |> 
  dplyr::select(FATAL, everything()) |> 
  rename_all(toupper)  |> 
  filter(WARD != "Unknown") -> dataframe12

unique(df_analysis$PERSONTYPE)
unique(df_analysis$WARD)
unique(df_analysis$SPEEDING_INVOLVED)

```


```{r}
logit_summary <- glm(FATAL ~ TIME_PERIOD + MONTH + SPEEDING_INVOLVED + AGE + WARD + PERSONTYPE, data = df_analysis, family = "binomial")
summary(logit_summary)
tidy(logit_summary)
```

## Summary Table
```{r}
sum.table <- tidy(logit_summary) |> 
  mutate(p.value = round(p.value, digits = 5),
         estimate = round(estimate, digits = 5)) |> 
  dplyr::arrange(p.value) |> 
  filter(p.value < 0.1) |> 
    knitr::kable("latex", booktabs = T) %>%
  kable_styling() %>%
  save_kable(file = "../Output/initial.table.png",
             zoom = 1.5,
             bs_theme = "Sandstone")

```

```{r}
glance(fatal_logit) |> 
  knitr::kable("latex", booktabs = T) %>%
  kable_styling() %>%
  save_kable(file = "glance3.png",
             zoom = 1.5,
             bs_theme = "Sandstone")
```

```{r}
logout1 <- augment(fatal_logit)
```


# Ridge
```{r}
library(MASS)
# include:false
rr <-  lm.ridge(FATAL ~ ., lambda=seq(0,100,1), data = df_analysis)
head(rr$coef, n=6)
```

```{r}
broom::tidy(rr)
plot(rr)
```

```{r}
MASS::select(rr)
```

```{r}
ggthemr("fresh")

ggplot(broom::tidy(rr), 
       aes(x = lambda, y = GCV)) +
  geom_line() +
  geom_vline(xintercept = broom::tidy(rr)$lambda[which.min(broom::tidy(rr)$GCV)],
             color = "red", lty = 2)
```



```{r}

library(MASS)
# include:false
rr <-  lm.ridge(FATAL ~ ., lambda=seq(390,425,1), data = df_analysis)
head(rr$coef, n=6)
MASS::select(rr)
ggplot(broom::tidy(rr), 
       aes(x = lambda, y = GCV)) +
  geom_line() +
  geom_vline(xintercept = broom::tidy(rr)$lambda[which.min(broom::tidy(rr)$GCV)],
             color = "red", lty = 2)
```


```{r}
reg <- glm(FATAL ~ ., data = df_analysis) 
x <- model.matrix(reg)
dim(x)
y <- df_analysis$FATAL

rr <- glmnet(x, y, alpha = 0)
```
```{r}
plot(rr, label = TRUE)
plot(rr, xvar = "lambda", label = TRUE)
```
```{r}
set.seed(123)
rr_cv <- cv.glmnet(x, y, alpha=0)
rr_cv
```
```{r}
plot(rr_cv)
```
```{r}
coef(rr_cv)
coef(rr_cv, s = "lambda.min") 
coef(rr_cv) |> as.matrix()
sum(coef(rr_cv)^2) - sum(coef(rr_cv, s = "lambda.min")^2)
rr_cv$cvm[rr_cv$index[2]] - rr_cv$cvm[rr_cv$index[1]]

```

```{r}
library(glmnet)
reg <- lm(FATAL ~ ., data = df_analysis) 
fit <- glmnet(x, y, family = "binomial", alpha = 1)

x <- model.matrix(reg)
dim(x)
```





# KNN Classification

```{r}
library(tidymodels)
data_split <- initial_split(df_analysis, prop = 2/3)
data_train <- training(data_split)
data_test <- testing(data_split)
```

```{r}
cl = data_train$FATAL  # Our training set y
knn(data_train, data_test, cl, k = 10) #same as before
knn(train, test, cl, k = 3) # different than before
```

```{r}

knnPredict <- predict(knnFit,newdata = DC_Test )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, DC_Test$FATAL )
```


```{r}
#Data Spilt for random trees 
set.seed(1234)

data_split <- initial_split(df_analysis, prop = 0.7)

DC_Train <- training(data_split)
DC_Test <- testing(data_split)

```

```{r}
#Tree Classification
tree <- rpart(FATAL ~., data = DC_Train)
rpart.plot(tree)

#Not sure how to make this bigger
```

```{r}
printcp(tree)

#Classification tree:
rpart(formula = FATAL ~ ., data = DC_Train)

plotcp(tree)

```

```{r}
#Model selction using the minimum CP 
tree <- rpart(FATAL ~., data = DC_Train,cp=0.010000)
```

```{r}
#Model Accuray 
p <- predict(tree, DC_Test, type = 'class')
confusionMatrix (p, DC_Test$FATAL, positive = 'Y')
```

# Street Lights and Cases

```{r}
lights.accident<- read_rds("../Data/lights.accident.rds")

p1 <- lights.accident |> 
  ggplot(aes(x = s.lights, y = actd.cases))+
  geom_point()+
  geom_smooth(formula = 'y ~ x',method = 'loess')+
  labs(x = "",
       y = "Numbers of Street Lights",
       title = "Numbers of Accident during 5 PM - 6 AM ")

p2 <- lights.accident |> 
  ggplot(aes(x = s.lights, y = actd.cases, color = WARD))+
  geom_point()+
  geom_smooth(formula = 'y ~ x',method = 'loess')+
  theme(legend.position = "bottom")+
   labs(x = "Numbers of Accident",
       y = "Numbers of Street Lights", 
       title = "Categorized by Ward")+
  theme(plot.title = element_text(hjust = 0.5))
ggthemr("fresh")


grid.arrange(p1, p2, nrow=2)


```

```{r}
lights.accident.lm <- lm(actd.cases ~ s.lights, data = lights.accident)
tidy(summary(lights.accident.lm)) |> 
  knitr::kable("latex", booktabs = T) %>%
  kable_styling() %>%
  save_kable(file = "../Output/lights.accident.lm.png",
             zoom = 1.5,
             bs_theme = "Sandstone")
```
# Plot

```{r}
ggthemr("fresh")
df_dc3 |> 
  ggplot(aes(x = AGE))+
  geom_histogram(bins = 30)+
  labs(x = "Age", y = "Numbers of Drivers" ,
       title = "Distribution of Drivers by Age")+
  theme(plot.title = element_text(hjust = 0.5))
```

