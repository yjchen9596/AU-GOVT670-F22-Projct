---
title: "gvt620 Project"
author: "Concillia Mpofu"
date: "2022-12-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#Loading libraries
library(tidyverse)
library(ISLR)
library(tidymodels)
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(caret)
library(pROC)
library(tree)
```


```{r}
#Loading data
df_dc<- read_rds("../data_cleaning/cases.after2010.rds")

glimpse(df_dc)
```

```{r}
#Dropping the variables that are not useful for prediction or with many levels i.e Licence plate state, Vehicle type 
df_analysis<- df_dc %>%
dplyr::select(-c(PERSONID,MAR_ID, NEARESTINTSTREETNAME, NEARESTINTROUTEID, YCOORD, XCOORD, LONGITUDE,LATITUDE, ADDRESS, FROMDATE, REPORTDATE, X, Y, CCN,  MEASURE,OFFSET,VEHICLEID, date, time, year, CRIMEID, ROUTEID, INTAPPROACHDIRECTION, INVEHICLETYPE, LICENSEPLATESTATE  ))
glimpse(df_analysis)
```

```{r}
#Changing variables to factors
fact_vars <- c('WARD', 'SPEEDING_INVOLVED', 'PERSONTYPE', 'FATAL', 'MAJORINJURY', 'MINORINJURY', 'TICKETISSUED','SPEEDING','IMPAIRED', 'month', 'time_period')
df_analysis[,fact_vars] <- lapply(df_analysis[,fact_vars] , factor)
str(df_analysis)
```



```{r}
#Logistic Regression with the full data set
fatal_logit <- glm(FATAL ~ time_period + month + SPEEDING + IMPAIRED + AGE+ TOTAL_VEHICLES + TOTAL_BICYCLES + TOTAL_PEDESTRIANS + MAR_SCORE + WARD + TOTAL_GOVERNMENT, data = df_analysis, family = "binomial")

logit_sum<-summary(fatal_logit)
logit_sum
```
- Ward 7 & 8 According to the 2020 census data Ward 7 and 8 have the lowest income levels and very high poverty level in the District of Columbia. From our model it shows that it is the state with highest probabilities of having Fatal accidents. 

- Bikers are also at high risk of being involves in fatal accidents - there is need for DC to invest in bicycle safe cities. 

- Interestingly age has not much effect of cause of fatal accidents

_ Speeding is the number one factor with higher probabilities of be involved in Fatal accidents, for every accident that take place there is a probability of 2.71 if speeding.

- Night Driving isn't safe in DC with probabilities of 1.34 of being involved in a fatal accident. 

```{r}
#Chisquare of the Logit Model

lr.anova= anova(fatal_logit, test="Chisq") 
lr.anova 

#All the selcted variables are statistically significant 
```

KNN Classification

```{r}
#Data Processiing and Scaling 
trainX <- DC_Train[,names(DC_Train) != "Direction"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues
```

```{r}
#Model Tuning
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
knnFit <- train(FATAL ~ ., data = DC_Train, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)

#Output of kNN fit
knnFit
```

```{r}

knnPredict <- predict(knnFit,newdata = DC_Test )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, DC_Test$FATAL )
```


```{r}
#Data Spilt for random trees 
set.seed(1234)

data_split <- initial_split(df_analysis, prop = 0.7)

DC_Train <- training(data_split)
DC_Test <- testing(data_split)

```

```{r}
#Tree Classification
tree <- rpart(FATAL ~., data = DC_Train)
rpart.plot(tree)

#Not sure how to make this bigger
```
```{r}
printcp(tree)

#Classification tree:
rpart(formula = FATAL ~ ., data = DC_Train)

plotcp(tree)

```

```{r}
#Model selction using the minimum CP 
tree <- rpart(FATAL ~., data = DC_Train,cp=0.010000)
```

```{r}
#Model Accuray 
p <- predict(tree, DC_Test, type = 'class')
confusionMatrix (p, DC_Test$FATAL, positive = 'Y')
```

