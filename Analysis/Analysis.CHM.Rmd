---
title: "gvt620 Project"
author: "Concillia Mpofu"
date: "2022-12-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Loading libraries

```{r include=FALSE}
library(tidyverse)
library(ISLR)
library(tidymodels)
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(caret)
library(pROC)
library(tree)
library(broom)
library(kableExtra)
```

#Loading data

```{r}
df_dc<- read_rds("../Data/cases.after2010.rds")
glimpse(df_dc)
```

```{r}
#Dropping the variables that are not useful for prediction or with many levels i.e Licence plate state, Vehicle type 
df_analysis<- df_dc %>%
dplyr::select(-c(PERSONID,MAR_ID, NEARESTINTSTREETNAME, NEARESTINTROUTEID, YCOORD, XCOORD, LONGITUDE,LATITUDE, ADDRESS, FROMDATE, REPORTDATE, X, Y, CCN,  MEASURE,OFFSET,VEHICLEID, date, time, year, CRIMEID, ROUTEID, INTAPPROACHDIRECTION, INVEHICLETYPE, LICENSEPLATESTATE  ))
glimpse(df_analysis)
```

#Changing variables to factors

```{r}
fact_vars <- c('WARD', 'SPEEDING_INVOLVED', 'PERSONTYPE', 'FATAL', 'MAJORINJURY', 'MINORINJURY', 'TICKETISSUED','SPEEDING','IMPAIRED', 'month', 'time_period')
df_analysis[,fact_vars] <- lapply(df_analysis[,fact_vars] , factor)
# str(df_analysis)
```


#Logistic Regression 

```{r}
fatal_logit <- glm(FATAL ~ time_period + month + SPEEDING + IMPAIRED + AGE+ TOTAL_VEHICLES + TOTAL_BICYCLES + TOTAL_PEDESTRIANS + MAR_SCORE + WARD + TOTAL_GOVERNMENT, data = df_analysis, family = "binomial")

logit_sum<-summary(fatal_logit)
logit_sum 
```

```{r}
#Finding the log odds exponents 
t1 <- tbl_regression(fatal_logit, exponentiate = TRUE)

print(t1)
```


#Data Spilt - training and testing
```{r}

set.seed(1234)
data_split <- initial_split(df_analysis, prop = 0.7)
DC_Train <- training(data_split)
DC_Test <- testing(data_split)

```

#KNN Classification

```{r}
#Data Processing and Scaling 
trainX <- DC_Train[,names(DC_Train) != "Direction"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues
```

```{r}
#Model Training
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
knnFit <- train(FATAL ~ ., data = DC_Train, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)

#Output of kNN fit
knnFit
```

```{r}

knnPredict <- predict(knnFit,newdata = DC_Test )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, DC_Test$FATAL )
```

```{r}

```

```{r}
#Data Spilt for random trees 
set.seed(1234)

data_split <- initial_split(df_analysis, prop = 0.7)

DC_Train <- training(data_split)
DC_Test <- testing(data_split)

```

```{r}
#Tree Classification
tree <- rpart(FATAL ~., data = DC_Train)
rpart.plot(tree)

#Not sure how to make this bigger
```
```{r}
printcp(tree)
```


```{r}
#Classification tree:
rpart(formula = FATAL ~ ., data = DC_Train)
```


```{r}
plotcp(tree)

```

```{r}
#Model selction using the minimum CP 
tree <- rpart(FATAL ~., data = DC_Train,cp=0.010000)
```

```{r}
#Model Accuray 
p <- predict(tree, DC_Test, type = 'class')
confusionMatrix (p, DC_Test$FATAL, positive = 'Y')
```

